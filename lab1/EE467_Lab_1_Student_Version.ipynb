{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j_UUTq-PT1k"
      },
      "source": [
        "# EE 467 Lab 1: ML Pipeline for Spam Detection\n",
        "\n",
        "In this lab, we will go through the process of a typical machine learning task, and apply it to a cyber-security problem. We will build a binary classifier that detects spam emails. Like previous lab, we will leave out some code for you to complete. Refer to API references and search on Google for usage of libraries and functions. Refer to previous labs and search on Google for usage of libraries and functions, and ask TA or Instructor if you don't really have a clue.\n",
        "\n",
        "Before working on the code, we will need to install `NLTK` and `scikit-learn` for this lab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Zjx8guPT1m",
        "outputId": "f97ff580-1146-4711-e466-9e602ea9e7a0",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install nltk scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaEWTjp0PT1n"
      },
      "source": [
        "And ensure the dataset is extracted from the archive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9is6J72DPT1n",
        "outputId": "3e74a2b2-74b9-4e49-9a31-ae39d5e565cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n"
          ]
        }
      ],
      "source": [
        "# Extract data\n",
        "!tar -xf emails.tar.xz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRVyTUb3PT1n"
      },
      "source": [
        "Then import the libraries we will use here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGr3vz7gPT1n",
        "outputId": "fb868e66-706b-4c9b-92f3-f1d34f919aba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/main/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# IMPORT REQUIRED LIBRARIES\n",
        "# =============================================================================\n",
        "# string   - Python's built-in module for string operations (punctuation list)\n",
        "# numpy    - Numerical computing (we use 'np' as the standard alias)\n",
        "# pandas   - Data manipulation and analysis (we use 'pd' as the standard alias)\n",
        "# nltk     - Natural Language Toolkit for text processing\n",
        "# =============================================================================\n",
        "\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# NLTK (Natural Language Toolkit) - the most popular Python library for NLP\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stop words (common words like \"the\", \"a\", \"is\" that add no meaning)\n",
        "# These need to be downloaded once before use\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elnpAo5yPT1o"
      },
      "source": [
        "## Pre-processing\n",
        "\n",
        "All machine learning tasks begin with the **pre-processing** step, during which we load the dataset into memory and \"clean\" the data so that they are suitable for subsequent steps. For spam email detection task, here we will load all emails into the memory, tokenize each email into a list of words and then remove words that are useless for analysis.\n",
        "\n",
        "All emails are stored in `emails.csv` under the same directory as this notebook. Feel free to open the file, take a look and get familiar with the format of the email dataset, then go back here to load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH2gqphfPT1o",
        "outputId": "27958fe5-c749-45a5-abd5-099951240dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  spam\n",
            "0  Subject: naturally irresistible your corporate...     1\n",
            "1  Subject: the stock trading gunslinger  fanny i...     1\n",
            "2  Subject: unbelievable new homes made easy  im ...     1\n",
            "3  Subject: 4 color printing special  request add...     1\n",
            "4  Subject: do not have money , get software cds ...     1 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# LOADING THE DATASET\n",
        "# =============================================================================\n",
        "# pd.read_csv() reads a CSV file and returns a DataFrame\n",
        "# A DataFrame is like a spreadsheet - rows are samples, columns are features\n",
        "# =============================================================================\n",
        "\n",
        "# Load email dataset into a DataFrame\n",
        "df = pd.read_csv(\"emails.csv\")\n",
        "\n",
        "# Preview first 5 rows\n",
        "print(df.head(5), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOZgxL_vPT1o",
        "outputId": "fc2e59d8-2554-4777-c1f4-2b2e7e2c331b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (5728, 2)\n",
            "Columns: Index(['text', 'spam'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Check dataset size and columns\n",
        "print(\"Shape:\", df.shape)      # (rows, columns)\n",
        "print(\"Columns:\", df.columns)  # 'text' = email, 'spam' = label (1=spam, 0=ham)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FxaHyRLDPT1o"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WqVsI-LKPT1p"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text    0\n",
              "spam    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Number of missing (NAN, NaN, na) data for each column\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtoegYUOPT1p"
      },
      "source": [
        "After loading the email dataset into memory, we will need to remove punctuations and stop words from these emails. Stop words are common, useless words that should be ignored in analysis (such as a, an, the, ...)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xxXxXArePT1p"
      },
      "outputs": [],
      "source": [
        "# Text tokenizer: removes punctuation and stop words\n",
        "def process_text(text):\n",
        "    \"\"\"Convert email text to list of meaningful words.\"\"\"\n",
        "\n",
        "    # Remove punctuation (!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~)\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "\n",
        "    # Remove stop words (\"the\", \"a\", \"is\", etc.) - case insensitive\n",
        "    clean_words = [word for word in nopunc.split()\n",
        "                   if word.lower() not in stopwords.words('english')]\n",
        "\n",
        "    return clean_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "EWBnGCsePT1p",
        "outputId": "7d05f7f0-5011-4bcb-94b3-ad1773771351"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [Subject, naturally, irresistible, corporate, ...\n",
              "1    [Subject, stock, trading, gunslinger, fanny, m...\n",
              "2    [Subject, unbelievable, new, homes, made, easy...\n",
              "3    [Subject, 4, color, printing, special, request...\n",
              "4    [Subject, money, get, software, cds, software,...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview the result of tokenization\n",
        "df['text'].head().apply(process_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh4kfn-6PT1p"
      },
      "source": [
        "## Feature Extraction\n",
        "\n",
        "We have obtained semi-structured tokenized email texts in the pre-processing step; however, machine learning algorithms usually operate on fully-structured numerical features. Hence, we need to find a way to convert the email texts to numeric vectors. This process is called **feature extraction**, and is necessary in data mining and analysis tasks where input data is semi-structured or even unstructured. In the following part we will make use of `scikit-learn`, which is a library for classic machine learning and feature extraction.\n",
        "\n",
        "We will use **token count features** to represent the characteristics of each email. This turns a piece of text into a vector, each dimension of which contains the number of occurance of a particular word. In practice, we process many texts at once and end up getting a token count matrix. Below is simple demo on a toy dataset with only two emails:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SR5lKkFAPT1p"
      },
      "outputs": [],
      "source": [
        "# DEMO: Bag-of-Words converts text → word count vectors\n",
        "\n",
        "message4 = 'hello world hello hello world play'\n",
        "message5 = 'test test test test one hello'\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# CountVectorizer: text → matrix where each column = a word, values = counts\n",
        "cv = CountVectorizer(analyzer=process_text)\n",
        "bow4 = cv.fit_transform([[message4], [message5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUj5D0SBPT1p",
        "outputId": "080b5163-3fae-4e3e-f7d8-3cddb7c8057d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['hello' 'one' 'play' 'test' 'world'] \n",
            "\n",
            "[[3 0 1 0 2]\n",
            " [1 1 0 4 0]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Vocabulary = unique words (these become column names)\n",
        "print(cv.get_feature_names_out(), \"\\n\")\n",
        "\n",
        "# Count matrix: rows = documents, columns = word counts\n",
        "print(bow4.toarray(), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8IXHIprPT1p",
        "outputId": "a14d9c95-e1f4-4eb8-9513-4989a275b74b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 6 stored elements and shape (2, 5)>\n",
            "  Coords\tValues\n",
            "  (0, 0)\t3\n",
            "  (0, 4)\t2\n",
            "  (0, 2)\t1\n",
            "  (1, 0)\t1\n",
            "  (1, 3)\t4\n",
            "  (1, 1)\t1 <class 'scipy.sparse._csr.csr_matrix'> \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sparse format: only stores non-zero values (saves memory)\n",
        "print(bow4, type(bow4), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgfOHsqUPT1p"
      },
      "source": [
        "Now let's compute and store token count matrix for real data:\n",
        "\n",
        "## Create bag-of-words matrix for all emails\n",
        "\n",
        "In this step, you will convert the email **text content** into a **Bag-of-Words (BoW)** representation using `CountVectorizer`.\n",
        "\n",
        "✅ **Important note:**  \n",
        "In the in-class demo, we used `CountVectorizer(analyzer=process_text)`, where `process_text` performs custom text processing.  \n",
        "That approach can be **slow** and may produce **many printed outputs** because the custom analyzer shows intermediate processing steps.\n",
        "\n",
        "For this lab, we will use a simpler and faster approach by letting `CountVectorizer` handle the tokenization internally, and we will enable English stop-word removal using:\n",
        "\n",
        "- `stop_words=\"english\"`\n",
        "\n",
        "➡️ Your task: apply `CountVectorizer(stop_words=\"english\")` on the `text` column and store the result in `messages_bow` as a **sparse matrix**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9osgK5BsPT1p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 505786 stored elements and shape (5695, 36996)>\n",
            "  Coords\tValues\n",
            "  (0, 32145)\t1\n",
            "  (0, 23219)\t1\n",
            "  (0, 18705)\t1\n",
            "  (0, 9986)\t1\n",
            "  (0, 17562)\t1\n",
            "  (0, 21006)\t1\n",
            "  (0, 27817)\t1\n",
            "  (0, 16546)\t1\n",
            "  (0, 27941)\t1\n",
            "  (0, 9223)\t3\n",
            "  (0, 21520)\t2\n",
            "  (0, 32408)\t1\n",
            "  (0, 18103)\t1\n",
            "  (0, 18751)\t1\n",
            "  (0, 15964)\t2\n",
            "  (0, 7986)\t1\n",
            "  (0, 20818)\t3\n",
            "  (0, 32126)\t1\n",
            "  (0, 31776)\t1\n",
            "  (0, 24679)\t1\n",
            "  (0, 35805)\t2\n",
            "  (0, 21296)\t2\n",
            "  (0, 32839)\t1\n",
            "  (0, 12539)\t1\n",
            "  (0, 26937)\t2\n",
            "  :\t:\n",
            "  (5694, 24659)\t2\n",
            "  (5694, 21490)\t1\n",
            "  (5694, 5683)\t9\n",
            "  (5694, 30755)\t1\n",
            "  (5694, 2807)\t3\n",
            "  (5694, 13246)\t1\n",
            "  (5694, 13036)\t1\n",
            "  (5694, 17257)\t1\n",
            "  (5694, 14028)\t1\n",
            "  (5694, 20137)\t1\n",
            "  (5694, 31635)\t1\n",
            "  (5694, 13037)\t1\n",
            "  (5694, 20329)\t1\n",
            "  (5694, 35066)\t1\n",
            "  (5694, 8557)\t1\n",
            "  (5694, 29914)\t1\n",
            "  (5694, 13428)\t5\n",
            "  (5694, 35964)\t1\n",
            "  (5694, 943)\t2\n",
            "  (5694, 2776)\t1\n",
            "  (5694, 30109)\t1\n",
            "  (5694, 17456)\t1\n",
            "  (5694, 33710)\t1\n",
            "  (5694, 10293)\t1\n",
            "  (5694, 11304)\t1\n"
          ]
        }
      ],
      "source": [
        "cv = CountVectorizer(stop_words=\"english\")\n",
        "messages_bow = cv.fit_transform(df[\"text\"])\n",
        "print(messages_bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08AAR1-dPT1q"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that we have loaded and pre-processed the email dataset, it's time to **train** a classifier model that does the job. First, we will split the email dataset into a 80% **training set** and a 20% **test set**. Each set will contain sample features as well as corresponding labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KWKaFDkbPT1q"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into 80% training (X_train & y_train)\n",
        "# and 20% testing (X_test & y_test) data sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(messages_bow, df['spam'], test_size = 0.20, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-PwjtkEPT1q"
      },
      "source": [
        "Then, we train a **logistic regression** classifier on the training set. We determine the class of the sample through its probability which is computed from the following formula:\n",
        "\n",
        "$$\n",
        "P(Y = 1|X = x) = \\frac{e^{\\mathbf{X}^T \\mathbf{b}}}{(1+e^{\\mathbf{X}^T \\mathbf{b}})} \\\\\n",
        "P(Y = 0|X = x) = 1 - P(Y = 1|X = x)\n",
        "$$\n",
        "\n",
        "Where $\\mathbf{b}$ is a trainable vector. During training, we will try to maximize the **cross entropy loss** by performing **stochastic gradient descent** on parameter $\\mathbf{b}$:\n",
        "\n",
        "$$\n",
        "l_{CE} = -(y \\log P(Y = 1|X = x) + (1 - y) \\log P(Y = 0|X = x))\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2qJIq3TYPT1q",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "}\n",
              "\n",
              "#sk-container-id-1.light {\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: black;\n",
              "  --sklearn-color-background: white;\n",
              "  --sklearn-color-border-box: black;\n",
              "  --sklearn-color-icon: #696969;\n",
              "}\n",
              "\n",
              "#sk-container-id-1.dark {\n",
              "  --sklearn-color-text-on-default-background: white;\n",
              "  --sklearn-color-background: #111;\n",
              "  --sklearn-color-border-box: white;\n",
              "  --sklearn-color-icon: #878787;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: center;\n",
              "  justify-content: center;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  display: none;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  overflow: visible;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-0);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-0);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".estimator-table {\n",
              "    font-family: monospace;\n",
              "}\n",
              "\n",
              ".estimator-table summary {\n",
              "    padding: .5rem;\n",
              "    cursor: pointer;\n",
              "}\n",
              "\n",
              ".estimator-table summary::marker {\n",
              "    font-size: 0.7rem;\n",
              "}\n",
              "\n",
              ".estimator-table details[open] {\n",
              "    padding-left: 0.1rem;\n",
              "    padding-right: 0.1rem;\n",
              "    padding-bottom: 0.3rem;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table {\n",
              "    margin-left: auto !important;\n",
              "    margin-right: auto !important;\n",
              "    margin-top: 0;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:nth-child(odd) {\n",
              "    background-color: #fff;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:nth-child(even) {\n",
              "    background-color: #f6f6f6;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:hover {\n",
              "    background-color: #e0e0e0;\n",
              "}\n",
              "\n",
              ".estimator-table table td {\n",
              "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
              "}\n",
              "\n",
              "/*\n",
              "    `table td`is set in notebook with right text-align.\n",
              "    We need to overwrite it.\n",
              "*/\n",
              ".estimator-table table td.param {\n",
              "    text-align: left;\n",
              "    position: relative;\n",
              "    padding: 0;\n",
              "}\n",
              "\n",
              ".user-set td {\n",
              "    color:rgb(255, 94, 0);\n",
              "    text-align: left !important;\n",
              "}\n",
              "\n",
              ".user-set td.value {\n",
              "    color:rgb(255, 94, 0);\n",
              "    background-color: transparent;\n",
              "}\n",
              "\n",
              ".default td {\n",
              "    color: black;\n",
              "    text-align: left !important;\n",
              "}\n",
              "\n",
              ".user-set td i,\n",
              ".default td i {\n",
              "    color: black;\n",
              "}\n",
              "\n",
              "/*\n",
              "    Styles for parameter documentation links\n",
              "    We need styling for visited so jupyter doesn't overwrite it\n",
              "*/\n",
              "a.param-doc-link,\n",
              "a.param-doc-link:link,\n",
              "a.param-doc-link:visited {\n",
              "    text-decoration: underline dashed;\n",
              "    text-underline-offset: .3em;\n",
              "    color: inherit;\n",
              "    display: block;\n",
              "    padding: .5em;\n",
              "}\n",
              "\n",
              "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
              "a.param-doc-link::before {\n",
              "    position: absolute;\n",
              "    content: \"\";\n",
              "    inset: 0;\n",
              "}\n",
              "\n",
              ".param-doc-description {\n",
              "    display: none;\n",
              "    position: absolute;\n",
              "    z-index: 9999;\n",
              "    left: 0;\n",
              "    padding: .5ex;\n",
              "    margin-left: 1.5em;\n",
              "    color: var(--sklearn-color-text);\n",
              "    box-shadow: .3em .3em .4em #999;\n",
              "    width: max-content;\n",
              "    text-align: left;\n",
              "    max-height: 10em;\n",
              "    overflow-y: auto;\n",
              "\n",
              "    /* unfitted */\n",
              "    background: var(--sklearn-color-unfitted-level-0);\n",
              "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              "/* Fitted state for parameter tooltips */\n",
              ".fitted .param-doc-description {\n",
              "    /* fitted */\n",
              "    background: var(--sklearn-color-fitted-level-0);\n",
              "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".param-doc-link:hover .param-doc-description {\n",
              "    display: block;\n",
              "}\n",
              "\n",
              ".copy-paste-icon {\n",
              "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
              "    background-repeat: no-repeat;\n",
              "    background-size: 14px 14px;\n",
              "    background-position: 0;\n",
              "    display: inline-block;\n",
              "    width: 14px;\n",
              "    height: 14px;\n",
              "    cursor: pointer;\n",
              "}\n",
              "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
              "        <div class=\"estimator-table\">\n",
              "            <details>\n",
              "                <summary>Parameters</summary>\n",
              "                <table class=\"parameters-table\">\n",
              "                  <tbody>\n",
              "                    \n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('penalty',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=penalty,-%7B%27l1%27%2C%20%27l2%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
              "            penalty\n",
              "            <span class=\"param-doc-description\">penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'<br><br>Specify the norm of the penalty:<br><br>- `None`: no penalty is added;<br>- `'l2'`: add a L2 penalty term and it is the default choice;<br>- `'l1'`: add a L1 penalty term;<br>- `'elasticnet'`: both L1 and L2 penalty terms are added.<br><br>.. warning::<br>   Some penalties may not work with some solvers. See the parameter<br>   `solver` below, to know the compatibility between the penalty and<br>   solver.<br><br>.. versionadded:: 0.19<br>   l1 penalty with SAGA solver (allowing 'multinomial' + L1)<br><br>.. deprecated:: 1.8<br>   `penalty` was deprecated in version 1.8 and will be removed in 1.10.<br>   Use `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for<br>   `penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for<br>   `'penalty='elasticnet'`.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('C',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
              "            C\n",
              "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Inverse of regularization strength; must be a positive float.<br>Like in support vector machines, smaller values specify stronger<br>regularization. `C=np.inf` results in unpenalized logistic regression.<br>For a visual example on the effect of tuning the `C` parameter<br>with an L1 penalty, see:<br>:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">1.0</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('l1_ratio',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=l1_ratio,-float%2C%20default%3D0.0\">\n",
              "            l1_ratio\n",
              "            <span class=\"param-doc-description\">l1_ratio: float, default=0.0<br><br>The Elastic-Net mixing parameter, with `0 <= l1_ratio <= 1`. Setting<br>`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.<br>Any value between 0 and 1 gives an Elastic-Net penalty of the form<br>`l1_ratio * L1 + (1 - l1_ratio) * L2`.<br><br>.. warning::<br>   Certain values of `l1_ratio`, i.e. some penalties, may not work with some<br>   solvers. See the parameter `solver` below, to know the compatibility between<br>   the penalty and solver.<br><br>.. versionchanged:: 1.8<br>    Default value changed from None to 0.0.<br><br>.. deprecated:: 1.8<br>    `None` is deprecated and will be removed in version 1.10. Always use<br>    `l1_ratio` to specify the penalty type.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">0.0</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('dual',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=dual,-bool%2C%20default%3DFalse\">\n",
              "            dual\n",
              "            <span class=\"param-doc-description\">dual: bool, default=False<br><br>Dual (constrained) or primal (regularized, see also<br>:ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation<br>is only implemented for l2 penalty with liblinear solver. Prefer `dual=False`<br>when n_samples > n_features.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">False</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('tol',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
              "            tol\n",
              "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for stopping criteria.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">0.0001</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('fit_intercept',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
              "            fit_intercept\n",
              "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Specifies if a constant (a.k.a. bias or intercept) should be<br>added to the decision function.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">True</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('intercept_scaling',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=intercept_scaling,-float%2C%20default%3D1\">\n",
              "            intercept_scaling\n",
              "            <span class=\"param-doc-description\">intercept_scaling: float, default=1<br><br>Useful only when the solver `liblinear` is used<br>and `self.fit_intercept` is set to `True`. In this case, `x` becomes<br>`[x, self.intercept_scaling]`,<br>i.e. a \"synthetic\" feature with constant value equal to<br>`intercept_scaling` is appended to the instance vector.<br>The intercept becomes<br>``intercept_scaling * synthetic_feature_weight``.<br><br>.. note::<br>    The synthetic feature weight is subject to L1 or L2<br>    regularization as all other features.<br>    To lessen the effect of regularization on synthetic feature weight<br>    (and therefore on the intercept) `intercept_scaling` has to be increased.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">1</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('class_weight',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
              "            class_weight\n",
              "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one.<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.<br><br>.. versionadded:: 0.17<br>   *class_weight='balanced'*</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"user-set\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('random_state',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
              "            random_state\n",
              "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the<br>data. See :term:`Glossary <random_state>` for details.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">0</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('solver',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver,-%7B%27lbfgs%27%2C%20%27liblinear%27%2C%20%27newton-cg%27%2C%20%27newton-cholesky%27%2C%20%27sag%27%2C%20%27saga%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27lbfgs%27\">\n",
              "            solver\n",
              "            <span class=\"param-doc-description\">solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'<br><br>Algorithm to use in the optimization problem. Default is 'lbfgs'.<br>To choose a solver, you might want to consider the following aspects:<br><br>- 'lbfgs' is a good default solver because it works reasonably well for a wide<br>  class of problems.<br>- For :term:`multiclass` problems (`n_classes >= 3`), all solvers except<br>  'liblinear' minimize the full multinomial loss, 'liblinear' will raise an<br>  error.<br>- 'newton-cholesky' is a good choice for<br>  `n_samples` >> `n_features * n_classes`, especially with one-hot encoded<br>  categorical features with rare categories. Be aware that the memory usage<br>  of this solver has a quadratic dependency on `n_features * n_classes`<br>  because it explicitly computes the full Hessian matrix.<br>- For small datasets, 'liblinear' is a good choice, whereas 'sag'<br>  and 'saga' are faster for large ones;<br>- 'liblinear' can only handle binary classification by default. To apply a<br>  one-versus-rest scheme for the multiclass setting one can wrap it with the<br>  :class:`~sklearn.multiclass.OneVsRestClassifier`.<br><br>.. warning::<br>   The choice of the algorithm depends on the penalty chosen (`l1_ratio=0`<br>   for L2-penalty, `l1_ratio=1` for L1-penalty and `0 < l1_ratio < 1` for<br>   Elastic-Net) and on (multinomial) multiclass support:<br><br>   ================= ======================== ======================<br>   solver            l1_ratio                 multinomial multiclass<br>   ================= ======================== ======================<br>   'lbfgs'           l1_ratio=0               yes<br>   'liblinear'       l1_ratio=1 or l1_ratio=0 no<br>   'newton-cg'       l1_ratio=0               yes<br>   'newton-cholesky' l1_ratio=0               yes<br>   'sag'             l1_ratio=0               yes<br>   'saga'            0<=l1_ratio<=1           yes<br>   ================= ======================== ======================<br><br>.. note::<br>   'sag' and 'saga' fast convergence is only guaranteed on features<br>   with approximately the same scale. You can preprocess the data with<br>   a scaler from :mod:`sklearn.preprocessing`.<br><br>.. seealso::<br>   Refer to the :ref:`User Guide <Logistic_regression>` for more<br>   information regarding :class:`LogisticRegression` and more specifically the<br>   :ref:`Table <logistic_regression_solvers>`<br>   summarizing solver/penalty supports.<br><br>.. versionadded:: 0.17<br>   Stochastic Average Gradient (SAG) descent solver. Multinomial support in<br>   version 0.18.<br>.. versionadded:: 0.19<br>   SAGA solver.<br>.. versionchanged:: 0.22<br>   The default solver changed from 'liblinear' to 'lbfgs' in 0.22.<br>.. versionadded:: 1.2<br>   newton-cholesky solver. Multinomial support in version 1.6.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('max_iter',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
              "            max_iter\n",
              "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>Maximum number of iterations taken for the solvers to converge.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">100</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('verbose',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
              "            verbose\n",
              "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>For the liblinear and lbfgs solvers set verbose to any positive<br>number for verbosity.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">0</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('warm_start',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
              "            warm_start\n",
              "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>Useless for liblinear solver. See :term:`the Glossary <warm_start>`.<br><br>.. versionadded:: 0.17<br>   *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">False</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('n_jobs',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">\n",
              "        <a class=\"param-doc-link\"\n",
              "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
              "            n_jobs\n",
              "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Does not have any effect.<br><br>.. deprecated:: 1.8<br>   `n_jobs` is deprecated in version 1.8 and will be removed in 1.10.</span>\n",
              "        </a>\n",
              "    </td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "                  </tbody>\n",
              "                </table>\n",
              "            </details>\n",
              "        </div>\n",
              "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
              "    // Get the parameter prefix from the closest toggleable content\n",
              "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
              "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
              "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
              "\n",
              "    const originalStyle = element.style;\n",
              "    const computedStyle = window.getComputedStyle(element);\n",
              "    const originalWidth = computedStyle.width;\n",
              "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
              "\n",
              "    navigator.clipboard.writeText(fullParamName)\n",
              "        .then(() => {\n",
              "            element.style.width = originalWidth;\n",
              "            element.style.color = 'green';\n",
              "            element.innerHTML = \"Copied!\";\n",
              "\n",
              "            setTimeout(() => {\n",
              "                element.innerHTML = originalHTML;\n",
              "                element.style = originalStyle;\n",
              "            }, 2000);\n",
              "        })\n",
              "        .catch(err => {\n",
              "            console.error('Failed to copy:', err);\n",
              "            element.style.color = 'red';\n",
              "            element.innerHTML = \"Failed!\";\n",
              "            setTimeout(() => {\n",
              "                element.innerHTML = originalHTML;\n",
              "                element.style = originalStyle;\n",
              "            }, 2000);\n",
              "        });\n",
              "    return false;\n",
              "}\n",
              "\n",
              "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
              "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
              "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
              "    const paramName = element.parentElement.nextElementSibling\n",
              "        .textContent.trim().split(' ')[0];\n",
              "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
              "\n",
              "    element.setAttribute('title', fullParamName);\n",
              "});\n",
              "\n",
              "\n",
              "/**\n",
              " * Adapted from Skrub\n",
              " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
              " * @returns \"light\" or \"dark\"\n",
              " */\n",
              "function detectTheme(element) {\n",
              "    const body = document.querySelector('body');\n",
              "\n",
              "    // Check VSCode theme\n",
              "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
              "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
              "\n",
              "    if (themeKindAttr && themeNameAttr) {\n",
              "        const themeKind = themeKindAttr.toLowerCase();\n",
              "        const themeName = themeNameAttr.toLowerCase();\n",
              "\n",
              "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
              "            return \"dark\";\n",
              "        }\n",
              "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
              "            return \"light\";\n",
              "        }\n",
              "    }\n",
              "\n",
              "    // Check Jupyter theme\n",
              "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
              "        return 'dark';\n",
              "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
              "        return 'light';\n",
              "    }\n",
              "\n",
              "    // Guess based on a parent element's color\n",
              "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
              "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
              "    if (match) {\n",
              "        const [r, g, b] = [\n",
              "            parseFloat(match[1]),\n",
              "            parseFloat(match[2]),\n",
              "            parseFloat(match[3])\n",
              "        ];\n",
              "\n",
              "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
              "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
              "\n",
              "        if (luma > 180) {\n",
              "            // If the text is very bright we have a dark theme\n",
              "            return 'dark';\n",
              "        }\n",
              "        if (luma < 75) {\n",
              "            // If the text is very dark we have a light theme\n",
              "            return 'light';\n",
              "        }\n",
              "        // Otherwise fall back to the next heuristic.\n",
              "    }\n",
              "\n",
              "    // Fallback to system preference\n",
              "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
              "}\n",
              "\n",
              "\n",
              "function forceTheme(elementId) {\n",
              "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
              "    if (estimatorElement === null) {\n",
              "        console.error(`Element with id ${elementId} not found.`);\n",
              "    } else {\n",
              "        const theme = detectTheme(estimatorElement);\n",
              "        estimatorElement.classList.add(theme);\n",
              "    }\n",
              "}\n",
              "\n",
              "forceTheme('sk-container-id-1');</script></body>"
            ],
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X=X_train, y=y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p45HPPxiPT1q"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Finally, we need to determine how good our classification model is. This is known as **evaluation**. We will use our trained model to make predictions for both training and testing data, and calculate various metrics with the predictions and actual labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YrwgOf3CPT1q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training prediction:\n",
            " [0 0 0 ... 0 0 0] \n",
            "\n",
            "Training actual:\n",
            " [0 0 0 ... 0 0 0] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print predictions on training data\n",
        "# `predict` function compute model predictions from input data\n",
        "print(\"Training prediction:\\n\", classifier.predict(X_train), \"\\n\")\n",
        "\n",
        "# Print the actual labels\n",
        "print(\"Training actual:\\n\", y_train.values, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03v6kf7KPT1q"
      },
      "source": [
        "There are a number of useful metrics for evaluation of binary classifiers, available through `classification_report`, `confusion_matrix` and `accuracy_score` functions:\n",
        "\n",
        "* **Confusion Matrix**: a matrix that indicates how many samples are correctly or incorrectly classified. The cell at $i$-th row and $j$-th column represents how many samples that belong to $i$-th class and are predicted as $j$-th class. For binary classification, the confusion matrix has only two columns and two rows:\n",
        "\n",
        "|Class|True               |False              |\n",
        "|-----|-------------------|-------------------|\n",
        "|True |True Positive (TP) |False Negative (FN)|\n",
        "|False|False Positive (FP)|True Negative (TN) |\n",
        "\n",
        "* **Accuracy**: proportion of samples that are correctly classified.\n",
        "\n",
        "$$\n",
        "Accuracy = \\frac{TP+TN}{TP+FP+TN+FN}\n",
        "$$\n",
        "\n",
        "* **Precision**: of all positive predictions, how many of them are actually correct?\n",
        "\n",
        "$$\n",
        "Precision = \\frac{TP}{TP+FP}\n",
        "$$\n",
        "\n",
        "* **Recall**: of all actually positive samples, how many of them are predicted correctly?\n",
        "\n",
        "$$\n",
        "Recall = \\frac{TP}{TP+FN}\n",
        "$$\n",
        "\n",
        "* **F1 Score**: the harmonic mean of precision and recall.\n",
        "\n",
        "$$\n",
        "F1 = \\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjGVNZnoPT1q"
      },
      "source": [
        "We first calculates and prints various metrics for training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_RRmxZqjPT1q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3457\n",
            "           1       1.00      1.00      1.00      1099\n",
            "\n",
            "    accuracy                           1.00      4556\n",
            "   macro avg       1.00      1.00      1.00      4556\n",
            "weighted avg       1.00      1.00      1.00      4556\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3457    0]\n",
            " [   0 1099]] \n",
            "\n",
            "Accuracy:  1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Predict and evaluate on training data\n",
        "pred = classifier.predict(X_train)\n",
        "\n",
        "# `classification_report` outputs classification metrics\n",
        "# such as precision, recall and F1 score\n",
        "print(classification_report(y_train, pred))\n",
        "\n",
        "# `confusion_matrix` outputs how many samples are correctly or incorrectly classified\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_train, pred), \"\\n\")\n",
        "\n",
        "# `accuracy` computes classification accuracy\n",
        "print('Accuracy: ', accuracy_score(y_train, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os791MNHPT1q"
      },
      "source": [
        "We now calculates and prints the same metrics for testing data. This measures the ability of the classification model to generalize to similar yet unknown data. The less difference in training and testing data, the better the model is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "df8bCez2PT1q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training prediction:\n",
            " [1 0 0 ... 0 0 0] \n",
            "\n",
            "Training actual:\n",
            " [1 0 0 ... 0 0 0] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print predictions on training data\n",
        "# `predict` function compute model predictions from input data\n",
        "print(\"Training prediction:\\n\", classifier.predict(X_test), \"\\n\")\n",
        "\n",
        "# Print the actual labels\n",
        "print(\"Training actual:\\n\", y_test.values, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rK0oRo-jPT1q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       870\n",
            "           1       0.98      0.98      0.98       269\n",
            "\n",
            "    accuracy                           0.99      1139\n",
            "   macro avg       0.99      0.99      0.99      1139\n",
            "weighted avg       0.99      0.99      0.99      1139\n",
            "\n",
            "Confusion Matrix: \n",
            " [[865   5]\n",
            " [  5 264]] \n",
            "\n",
            "Accuracy:  0.9912203687445127\n"
          ]
        }
      ],
      "source": [
        "# Predict and evaluate on training data\n",
        "pred = classifier.predict(X_test)\n",
        "\n",
        "# `classification_report` outputs classification metrics\n",
        "# such as precision, recall and F1 score\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "# `confusion_matrix` outputs how many samples are correctly or incorrectly classified\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, pred), \"\\n\")\n",
        "\n",
        "# `accuracy` computes classification accuracy\n",
        "print('Accuracy: ', accuracy_score(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od8bz8ieTNui"
      },
      "source": [
        "## Discussion Question: Why Bag-of-Words (BoW) Still Works (and its Limitations)\n",
        "\n",
        "In this lab, we used **Bag-of-Words (BoW)** to convert email text into numerical features that a machine learning model can understand.\n",
        "\n",
        "### A common concern with BoW\n",
        "In the in-class discussion, we learned that some words appear in **many** documents (examples: *“the”*, *“and”*, *“hello”*, *“thanks”*). These very frequent words can cause two issues:\n",
        "\n",
        "1. **They do not help distinguish spam vs. ham**  \n",
        "   If a word appears in almost every email, it does not provide useful information for classification.\n",
        "\n",
        "2. **Different emails can look similar in feature space**  \n",
        "   Two different messages may share many common words, which can lead to **similar BoW representations**, even if their meaning is different.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Your Task (Short Answer)\n",
        "Even with the limitations above, BoW often performs surprisingly well for spam detection.\n",
        "\n",
        "**Why does the Bag-of-Words method still work well in this lab?**  \n",
        "Write a **short explanation** (2–4 sentences) and include **at least one clear reason** supported by what you observe in the dataset or model behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q7rbT8NWCB-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True positive\n",
            "1 1\n",
            "Subject: please read : newsletter regarding smallcaps  small - cap stock finder  new developments expected to move western sierra mining , inc . stock  from 0 . 70 to over 4 . 00  westernsierramining . com  western sierra mining is a company on the move , fast ! big news is out !  big business is afoot for wsrm !  read on to find out why wsrm is our top pick this week .  * western sierra mining has a very profitable business model in which  they avoid the highest cost associate with mining : exploration .  essentially , wester sierra operates mines on sites that have been previously  explored and found to be \" too small \" for the largest mining companies ,  yet still produce handsome profits .  * the global mining industry boom will continue for the foreseeable  future due to the impact of china - driven demand on commodity prices and  long supply - response lead times .  * news ! news ! news ! read on to find out why we expect wsrm to take off  this week !  here is recent news on the company :  phoenix - - ( business wire ) - - june 15 , 2005 - - western sierra mining corp .  ( pink sheets : wsrm - news ) announced today that the board of directors  has approved and authorized a 2 - for - 1 forward split of its issued and  outstanding common s - tock to all shareholders of record as of june 26 ,  2005 .  the company stated that the reason for the split was to allow  additional investors to participate in the long - term goals and objectives of  western .  phoenix - - ( business wire ) - - june 10 , 2005 - - western sierra mining ( pink  sheets : wsrm - news ) and oretech inc . ( pink sheets : orte - news )  announced today that their respective boards of directors have agreed to enter  into an agreement to develop the silver plume and pittsburg mines  located in colorado .  commenting on the proposed transaction , the president of western sierra  mining , michael chaffee , said , \" the new alignment with oretech will  allow each of the companies to utilize their specific expertise to the  maximum benefit of the other . oretech is trying to focus on developing its  propriety extraction technology and western is expanding its mining  activities in the u . s . we have started our due diligence on the property  and look forward to taking a proposal back to oretech by the end of the  month .  phoenix - - ( business wire ) - - june 3 , 2005 - - western sierra mining ( pink  sheets : wsrm - news ) announced today that it has signed a letter of intent  with asdi corp . providing wsrm the right to develop the asdi property  located in crescent valley at battle mountain , nev .  we cannot stress enough the significance of this news . a s - tock split  can only mean one thing ; good business ! with the split date set at june  26 , now is obviously the time to get in . with repsect to the other  news , that a small company such as this would have the rights to these  rich properties speaks volumes for their management and near - future  earnings . that they would be so fortunate as to be involved with an industry  pioneer such as oretech is nothing short of extraordinary .  these fortuitous events have earned wsrm our highly recommendation  symbol : ( wsrm )  current price : 0 . 70  short term target price : 4 . 60  12 month target price : 8 . 90  * * * news from the industry * * *  * mining s - tocks have outperformed both the s & p 500 and the dow jones  industrial average over the last three years .  * profits by mining companies have doubled for the second year in a  row . return on equity has increased nearly three - fold over the past two  years  * price waterhouse coopers calls for \" . . . another bumper year for the  global mining industry in 2005 . \" they go on to say , \" the sustained  upturn in commodity prices has caught investors ' attention , creating a dash  for mining s - tocks . add the unprecedented profits and free cash flows  and we have a very buoyant industry . \"  for more information read , mine - enter the dragon , by price waterhouse  coopers , located at pwcglobal . com  disclaimer :  information within this email contains \" forward looking statements \"  within the meaning of section 27 a of the securities act of 1933 and  section 21 b of the securities exchange act of 1934 . any statements that  express or involve discussions with respect to predictions ,  expectations , beliefs , plans , projections , objectives , goals ,  assumptions or future  events or performance are not statements of historical fact and may be  \" forward looking statements . \" forward looking statements are based on  expectations , estimates and projections at the time the statements are  made that involve a number of risks and uncertainties which could cause  actual results or events to differ materially from those presently  anticipated . forward looking statements in this action may be  identified  through the use of words such as \" projects \" , \" foresee \" , \" expects \" ,  \" will , \" \" anticipates , \" \" estimates , \" \" believes , \" \" understands \" or  that by  statements indicating certain actions \" may , \" \" could , \" or \" might \" occur .  as with many micro - cap s - tocks , today ' s company has additional risk  factors worth noting . those factors include : a limited operating  history ,  the company advancing cash to related parties and a shareholder on an  unsecured basis : one vendor , a related party through a majority  s - tockholder , supplies ninety - seven percent of the company ' s raw  materials :  reliance on two customers for over fifty percent of their business and  numerous related party transactions and the need to raise capital .  these  factors and others are more fully spelled out in the company ' s sec  filings . we urge you to read the filings before you invest . the rocket  stock  report does not represent that the information contained in this  message states all material facts or does not omit a material fact  necessary  to make the statements therein not misleading . all information  provided within this email pertaining to investing , stocks , securities  must be  understood as information provided and not investment advice . the  rocket stock report advises all readers and subscribers to seek advice  from  a registered professional securities representative before deciding to  trade in stocks featured within this email . none of the material within  this report shall be construed as any kind of investment advice or  solicitation . many of these companies are on the verge of bankruptcy .  you  can lose all your mone * y by investing in this stock . the publisher of  the rocket stock report is not a registered investment advisor .  subscribers should not view information herein as legal , tax ,  accounting or  investment advice . any reference to past performance ( s ) of companies  are  specially selected to be referenced based on the favorable performance  of  these companies . you would need perfect timing to achieve the results  in the examples given . there can be no assurance of that happening .  remember , as always , past performance is never indicative of future  results and a thorough due diligence effort , including a review of a  company ' s filings , should be completed prior to investing . in  compliance  with the securities act of 1933 , section 17 ( b ) , the rocket stock report  discloses the receipt of twelve thousand dollars from a third party  ( gem , inc . ) , not an officer , director or affiliate shareholder for  the  circulation of this report . gem , inc . has a position in the stoc * k  they  will sell at any time without notice . be aware of an inherent conflict  of interest resulting from such compensation due to the fact that this  is a paid advertisement and we are conflicted . all factual information  in this report was gathered from public sources , including but not  limited to company websites , sec filings and company press releases .  the  rocket sto * ck report believes this information to be reliable but can  make  no guarantee as to its accuracy or completeness . use of the material  within this email constitutes your acceptance of these terms .\n",
            "\n",
            "True negative\n",
            "0 0\n",
            "Subject: schedule to chelmsford  hi all , here is what i have so far on the agenda front !  shirley , we need travel arrangement to attend the meeting mentioned below .  here are our prelimnary schedule .  please try to check us all in at the double tree in chelmsford , ma where the  meeting will be .  vince cannot attend . there will be four people from our group attending  including myself , stinson , krishna and samer . only stinson and i will attend  the dinner on monday night . here is the suggest times by names :  ravi & stinson :  leave houston around 12 : 00 pm on monday ( jan 31 , 2000 ) to be there for the  dinner . try to get us in chelmsford , ma in time so that we can attend the  dinner .  leave chelmsford , ma around 2 : 00 pm thursday .  one full size rental car for all four of us . you can put this in either mine  or stinson ' s name .  krishna & samer :  leave houston around 5 : 00 pm to get in time to get a good night sleep to  attend the meeting tue ( feb 1 ) :  leave chelmsford , ma either wed 6 : 00 pm or thurs afternoon depending on  individual schedule . krishna and samer , please let shirely know when you want  to get back . as long as you are there for tue and wed full day , you should  get enough out of the meeting .  shireley , please call me for more details .  regards ,  ravi .  - - - - - forwarded by ravi thuraisingham / enron communications on 01 / 27 / 00 04 : 45  pm - - - - -  phil markwart  01 / 26 / 00 08 : 00 pm  to : barb . vanbeyrer @ sycamorenet . com  cc : ravi thuraisingham / enron communications @ enron communications , erik  simpson / enron communications @ enron communications , stinson gibner / hou / ect @ ect  subject : schedule  please copy the persons in the cc line with the schedule of 31 jan as soon as  you get it .  at this point , you have told me :  31 jan travel to chelmsford and dinner around 7 pm ?  1 feb overall optical design considerations  2 feb specific route designs  3 feb more route design\n",
            "\n",
            "True negative\n",
            "0 0\n",
            "Subject: re : forecasting project  barbara ,  we are in touch with ketra and john and we shall work with them when they are  here .  vince  barbara g dillard @ enron  08 / 29 / 2000 11 : 23 am  to : mark mixon / hou / ees @ ees @ ect  cc : vince j kaminski / hou / ect @ ect , stinson gibner / hou / ect @ ect , laura  luce / corp / enron @ enron , d . wear @ pecorp . com @ ees @ ect ,  k . schmitt @ pecorp . com @ ees @ ect , j . wirick @ pecorp . com @ ees @ ect  subject : re : forecasting project  mark :  f . y . i . - i have been informed by ketra that she plans to be in the houston  office on monday september 18 th through wednesday september 20 th to meet with  vince and stinston .  hopefully we will be ready to continue phase i of the forecasting project .  can you make arrangements with vince and stinson ( hopefully they will be  available to meet ! ) .  thanks !  barbara  ( 312 ) 541 - 1232\n",
            "\n",
            "True positive\n",
            "1 1\n",
            "Subject: add logos and tones to your cell phone 1575332211111  take yourself out of our list by clicking here  bored  with  your cell phone ?  get  cool songs logos to your phone today !  it ' s  real simple ! no confusing downloads  or installations . simple phone activation !  click here to order  there  are tons of songs and graphics to choose from .  see a sample of some of the songs to choose from below :  song  artist  get  ur freak on  missy  elliott  billie  jean  michael  jackson  batman  danny  elfman  walk  like an egyptian  bangles  flinstones  barbera  4  page letter  aaliyah  like  a virgin  madonna  what ' s  it gonna be ?  b . rhymes / j . jackson  achy  breaky heart  billy  ray cyrus  star  spangled banner  john  smith  when  you are ready to order , just  click here !  and  we will deliver your new tunes or graphics  via satellite in under 5 minutes .  take yourself out of our list by clicking here \n",
            "\n",
            "True negative\n",
            "0 0\n",
            "Subject: summary of dabhol lenders ' presentation  vince / stinson ,  please find below a summary of the presenation given to lenders at the april  23 rd meeting in london .  the key points that emerge are :  phase ii will require commitments of about $ 700 mm to complete ( phase i + ii  total $ 3 . 2 billion )  several commercial issues are getting severe in the current environment in  india , could result in cost escalations  makes the case that mseb does not have the financial strength to absorb phase  ii power  management to seek authority to serve preliminary termination notice ( ptn ) ,  triggering a 6 month cure period  a copy of the full presenation is available .  regards ,  sandeep .\n",
            "\n",
            "True negative\n",
            "0 0\n",
            "Subject: ibuyit approvers  ah , these wonderful new systems ! i submitted an order on the \" new \" ibuyit  site and sent it for approval and it went to every manager in our group !  i called them and told them that only you were the approver and they do not  even have a user id set up for you . please fill out the below security document  and i will forward it on to them .  thanks !  shirley  - - - - - - - - - - - - - - - - - - - - - - forwarded by shirley crenshaw / hou / ect on 04 / 16 / 2001 03 : 26 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -  from : michael loft / enron @ enronxgate on 04 / 16 / 2001 03 : 18 pm  to : shirley crenshaw / hou / ect @ ect  cc :  subject : ibuyit approvers  hi shirley  in processing your ibuyit approval change request , i discovered that vince kaminski has not been set up with a user id in the eprocurement system . please have him fill out the attached security form and send it to - - sap security @ enron . com  i have already selected the approver role on the second page . we just need the personal information on page one filled out for security purposes . once this is done we can get vince assigned as the approver for cost center 107043 .  thanks ,  michael\n",
            "\n",
            "True negative\n",
            "0 0\n",
            "Subject: re : lacima energy and weather derivatives courses by clewlow and  strickland  sure :  i think that would be a great opportunity to get more insights on modeling  forward curves .  i would like to participate on both courses if possible .  many thanks for remembering my name .  paulo issler .  vince j kaminski  11 / 13 / 2000 08 : 15 am  to : paulo issler / hou / ect @ ect , alex huang / corp / enron @ enron  cc :  subject : lacima energy and weather derivatives courses by clewlow and  strickland  paulo , alex ,  any interest ?  vince  - - - - - - - - - - - - - - - - - - - - - - forwarded by vince j kaminski / hou / ect on 11 / 13 / 2000  08 : 22 am - - - - - - - - - - - - - - - - - - - - - - - - - - -  \" julie \" on 11 / 12 / 2000 02 : 05 : 40 pm  to :  cc :  subject : lacima energy and weather derivatives courses by clewlow and  strickland  please find attached information ? for our next two courses and workshops : ?  energy derivatives : ? pricing and risk management and  weather derivatives , which will be conducted in houston and in london in feb  / march 2001 . ? instructors will be dr les clewlow and dr chris strickland .  ?  because the course requires intense interaction , the courses will be ? limited  to a maximum of 15 people , so early registration is encouraged .  ?  if you require further information , or would like to register for either or  both ? courses , please contact me via this email or our web site , ? www .  lacimagroup . com  - energy . pdf  - weather . pdf\n",
            "\n",
            "True negative\n",
            "0 0\n",
            "Subject: eprm article  hi vince ,  ?  i ' m sorry you weren ' t around in sydney this week . you missed a very good  book launch party that john martin organised here for us . paul made a short  speech in which he relayed some great comments which he said came from ? you -  thanks very much !  ?  please find attached the next eprm article . its not really tided up fully  from our end yet , but i wanted to send it off before the weekend in case you  got chance to look at it . because of the easter break robin is after it by  thursday of next week .  ?  best regards .  ?  chris .  ?  - eprm _ 10 _ fwd _ curve _ simulation . doc\n",
            "\n",
            "True negative\n",
            "0 0\n",
            "Subject: seismic data via satellite  i am preparing a summary or our thursday discussions to be used as a  background piece for discussion / brainstorming with oil traders . i will  circulate this for review / correction later today , or , at the latest , monday .  greg , you mentioned that enron had participated in a speculative survey in  the gulf of mexico that was successful . it might be useful to get more info  on this . terms , return realized ( over what time frame ) , why we have not  continued to do this , etc .  also , from your comments , many , if not most of the 3 - d surveys are in deep  water . i read recently that shell , i believe , is participating in a deep sea  drilling / extraction project in the gulf . what oil price is required to make  these kinds of projects viable financially ?  bob lee\n",
            "\n",
            "True negative\n",
            "0 0\n",
            "Subject: internship opportunities  please respond to dear mr . kaminski ,  i have found the enrononline project a very interesting one and have enjoyed  working with everyone in the research department as well as those from other  departments . i am keenly interested in this area and was wondering if there  would be any summer internship opportunities . i have attached my resume to  this mail for your review and look forward to hearing from you soon .  thank you  ivy ghose  rice mba 2002  - resume . doc\n",
            "\n",
            "False negative\n",
            "Subject: out of office autoreply : just to her . . .  i am on vacation week 29 + 30 + 31 . please contact gerd madsen ( gm @ torben - rafn . dk ) or hans chr . jensen ( hcj @ torben - rafn . dk  your mail is not transfered .\n",
            "\n",
            "False positive\n",
            "Subject: fwd : fw : will you be the difference ?  fyi  jana  return - path :  received : from rly - yhol . mx . aol . com ( rly - yhol . mail . aol . com [ 172 . 18 . 147 . 33 ] )  by air - yhol . mail . aol . com ( v 76 _ rl . 8 ) with esmtp ; wed , 18 oct 2000 18 : 57 : 48  - 0400  received : from texasmonthly . emmis . com ( texasmonthly . emmis . com  [ 208 . 139 . 95 . 3 ] ) by rly - yhol . mx . aol . com ( v 76 _ rl . 19 ) with esmtp ; wed , 18 oct  2000 18 : 56 : 49 - 0400  subject : fw : will you be the difference ?  to : alexana @ wellsfargo . com , jlpnymex @ aol . com , kingair 500 @ aol . com ,  mdesanto @ minddata . com , kwgre @ aol . com , pmarb @ yahoo . com  x - mailer : lotus notes release 5 . 0 . 3 march 21 , 2000  message - id :  from : nalexander @ texasmonthly . emmis . com  date : wed , 18 oct 2000 18 : 15 : 34 - 0500  x - mimetrack : serialize by router on tmnto 2 / aus / txmo ( release 5 . 0 . 4 a | july 24 ,  2000 ) at 10 / 18 / 2000 05 : 54 : 02 pm  mime - version : 1 . 0  content - type : text / plain ; charset = us - ascii  texas monthly : if you want to be big in texas .  nancy alexander  account executive  214 . 871 . 7704  - - - - - forwarded by nancy alexander / aus / txmo on 10 / 18 / 00 06 : 14 pm - - - - -  karen burke  to : sloansimmo @ yahoo . com ,  ccgarcia @ prodigy . net , cbsbcol @ aol . com ,  10 / 18 / 00 sschrump @ ziplink . net , \" hosty , maria \"  ,  02 : 10 pm yvonne anguiano  ,  tanya . davis @ us . pwcglobal . com ,  2 onza @ pdq . net , \" lisa elledge \"  ,  proyecto 4 @ yahoo . com , \" hughes , jennifer \"  , anita  zmolek / aus / txmo @ txmo , nancy  alexander / aus / txmo @ txmo  cc :  subject : fw : will you be the  difference ?  texas monthly : if you want to be big in texas .  karen burke  713 . 871 . 1643 phone  713 . 871 . 0335 fax  - - - - - forwarded by karen burke / aus / txmo on 10 / 18 / 2000 02 : 08 pm - - - - -  jacquelyne  o ' keefe to : bassw @ swbell . net , karen  burke / aus / txmo @ txmo , elizabeth  wallace fulghum / aus / txmo @ txmo , lanette  varnadoe / aus / txmo @ txmo ,  simmonds @ pdq . net  10 / 18 / 2000 cc :  11 : 15 am subject : fw : will you be the  difference ?  texas monthly : if you want to be big in texas .  jackie o ' keefe wallace  retail advertising director  phone 713 . 871 . 1762  fax 713 . 871 . 0335  - - - - - forwarded by jacquelyne o ' keefe wallace / aus / txmo on 10 / 18 / 00 11 : 14 am  - - - - -  \" karen  thompson \" to : \" tim marron \"  , \" suzanne waller \"  , \" shelley smelley  marron \" ,  . net > \" pammy poindexter \"  , \" molly vaughan \"  , \" melissa  garlington \"  10 / 17 / 00  , \" mary marron \"  09 : 07 pm ,  \" margie \\ \" aunt boggie \\ \" marron \"  , \" liz rotan \"  , \" julia \"  , \" joanie seay \"  , \" jenny clark  brown \" ,  \" jackie wallace \"  ,  \" gmommy clark \"  , \" george kkempl 65 @ aol . com  ; jflesher @ kprc . com ;  akdwyer @ yahoo . com  ; cara _ clement @ yahoo . com ;  merrie @ mail . evl . net ; krichardson @ texasnf . org  ; kprice @ texasnf . org ;  ddeleon @ texasnf . org ; rfreeman @ texasnf . org  ; dbadura @ texasnf . org ; karen  thompson ; cmlucas @ swbell . net ;  annie 319 @ aol . com ; bmratch @ yahoo . com ;  sarah @ thedykes . com ; laura @ thebairds . com  ; mtucker @ datamate . com ;  colecaroline @ hotmail . com ;  mark . m . meador @ us . arthurandersen . com ;  robert muse ; dmoriniere @ swbank . tx . com  ; joanna latham ; merritt  pappas ; chip rives ; reagan rives  ; angela hilary and corey pond  ;  jeffrey smith ; kent winfield  date : tuesday , october 17 , 2000 3 : 37 pm  subject : fw : will you be the difference ?  >  >  > - - - - - original message - - - - -  > from : jennifer . p . toomey @ us . arthurandersen . com  > sent : tuesday , october 17 , 2000 3 : 53 pm  > to : aford @ bpl . com ; birdsbecca @ aol . com ; bwilliamsl 236 @ austin . rr . com ;  > ckmattingly @ hotmail . com ; cshirley @ ccj - law . com ; cwilliams @ texasnf . org ;  > ewells @ nrsc . org ; jill . goldstein @ mbao 2 . bus . utexas . edu ; halejulie @ yahoo . com ;  > hollyk 8 @ aol . com ; lsm 34 @ columbia . edu ; mtucker @ dpj . com ; sew 7 @ flash . net ;  > elizabeth . reid @ turner . com ; rskappraiser @ email . msn . com ; tehunt @ aol . com ;  > wdtiidd @ aol . com  > subject : fw : will you be the difference ?  >  >  >  >  >  > - - - - - - - - - - - - - - - - - - - - - - forwarded by jennifer p . toomey on 10 / 17 / 2000 03 : 55  > pm  > - - - - - - - - - - - - - - - - - - - - - - - - - - -  >  >  > to : brian _ seiler @ aimfunds . com , fritz _ weiss @ aimfunds . com ,  > jean _ miller @ aimfunds . com , charles _ hebert @ aimfunds . com ,  > sue _ hendrickson @ aimfunds . com , ralph _ terry @ aimfunds . com ,  > gormanab @ mindspring . com , alysonfisher @ yahoo . com , amandam @ microsoft . com ,  > adjohnso @ students . uiuc . edu , knocks @ ecsis . net , cbidding @ post . cis . smu . edu ,  > mpblalock @ aol . com , gmbl @ compassbnk . com , bcahal @ acxiom . com , carle @ wt . net ,  > cmiller @ rice . edu , connelly . mcgreevy @ gs . com , gnconnelly @ aol . com ,  > dawn . beach @ bowne . com , aimeedodson @ aol . com , ddominic @ temmc . com ,  > heather . k . doyle @ ac . com , aeasterby @ lrmm . com , ferikson @ mdanderson . org ,  > rtfass @ fcflaw . com , fguinn @ flash . net , tina . hoffman @ petrocosm . com ,  > rhurt @ lctn . com , wingram @ ddsep . com , jrcoastal @ aol . com , jennyv @ dpwpr . com ,  > jbandctaylor @ mindspring . com , keasterby @ aglife . com , jkiani @ coair . com ,  > kianim @ epenergy . com , kristen . kors @ weil . com , brittonk @ perryhomes . net ,  > katek @ . com , clipscomb @ kma . com ,  > kaymassmanlobb @ yahoo . com , mm 52 @ lucent . com , cjmandola @ aol . com ,  > mikebid @ earthlink . net , nataliebiddinger @ yahoo . com , steven . w . murray @ ac . com ,  > jpecher @ ect . enron . com , receskim @ perryhomes . net , jennifer p . toomey ,  > cvanos @ texas . net , jennyv @ dpwpr . com , kwehner @ brobeck . com ,  > elizabeth @ keen . com , david . d . wolf @ chase . com  > cc :  > date : 10 / 16 / 2000 09 : 00 am  > from : jackie _ mcgreevy @ aimfunds . com  > subject : fw : will you be the difference ?  >  >  >  >  >  > > the year is 1960 .  > >  > > jfk wins the election because he receives  > >  > > 1 more vote per precinct in illinois ( 8 , 858 votes )  > > 3 more votes per precinct in missouri ( 9 , 880 votes )  > > 3 more votes per precinct in new jersey ( 22 , 091 votes )  > >  > > without those 40 , 829 votes , the election goes to nixon .  > >  > > your vote does matter .  > >  > > experts say this will be the closest election since 1960 .  > > we agree .  > >  > > what can you do about it ? join the bush e - train !  > > ( 1 ) forward this e - mail to your friends and colleagues  > > ( 2 ) then click on the link below and enter your e - mail :  > > http : / / www . georgewbush . com / bn . asp ? pagemode = frontpagesignup  > >  > > our goal :  > > 2 , 000 , 000 e - mail addresses to spread the word  > > and get out the vote .  > >  > > be a part of history , get on the bush e - train and join  > > what will become one of the largest grassroots  > > movements ever .  > >  > > make the difference ! and receive the e - mail on  > > nov . 8 that says , \" president - elect george w . bush  > > thanks you . \"  > >  > >  > > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  > >  > > paid for by bush - cheney 2000 , inc .  > > http : / / www . georgewbush . com  > >  > >  >  =  > = =  > >  > > to unsubscribe , please go here :  > > http : / / www . georgewbush . com / unsubscribe . asp ? email = yolaa @ earthlink . net  > >  > > to change your e - mail address or any other subscription information ,  > please go here :  > > http : / / www . georgewbush . com / mygeorgew . asp  > >  > >  > >  >  >  >  >  >  >  >  >  > * * * * * * * * * * * * * * * * * * * internet email confidentiality  footer * * * * * * * * * * * * * * * * * * *  >  > privileged / confidential information may be contained in this message . if  > you  > are not the addressee indicated in this message ( or responsible for  delivery  > of  > the message to such person ) , you may not copy or deliver this message to  > anyone .  > in such case , you should destroy this message and kindly notify the sender  > by  > reply email . please advise immediately if you or your employer do not  > consent to  > internet email for messages of this kind . opinions , conclusions and other  > information in this message that do not relate to the official business of  > my  > firm shall be understood as neither given nor endorsed by it .  >  >  >\n",
            "\n",
            "False positive\n",
            "Subject: please approve : application request ( wsmh - 4 esnva )  security resource request wsmh - 4 esnva has been submitted for your approval .  to view the request , double click your left mouse button on the notes  document link below .  quick steps to approve or reject request form :  1 . click the button to view details of the requests .  2 . click the button to approve or reject the requests .  3 . to edit the request form , double - click anywhere on the form .  see the online help for instructions or call ect security .\n",
            "\n",
            "False negative\n",
            "Subject: delivery failure : user antonio _ lambino ( antonio _ lambino @ ksg . harvard . edu ) not  listed in domino directory  your message  subject : [ spam ] just to her . . .  was not delivered to :  antonio _ lambino @ ksg . harvard . edu  because :  user antonio _ lambino ( antonio _ lambino @ ksg . harvard . edu ) not listed in domino directory\n",
            "\n",
            "False negative\n",
            "Subject: een avontuurtje is oke ,  als je dit bericht niet kan lezen , klik hier .  je hebt dit bericht ontvangen omdat je in de db smsmag / kdotv bent . om uit te schrijven , klik hier . \n",
            "\n",
            "False positive\n",
            "Subject: 2001 budget for research  sir ,  i just got word that your bottom line needs to be 2 , 200 k . this is net of  corp charges and intercompany billings . in order to get to this number , we  have to reduce your budget by 83 k . do you have any suggestions in which  category ( ies ) we need to reduce ?  budget 10 , 521 , 000  i / c billings 8 , 238 , 000  subtotal 2 , 283 , 000  per delainey 2 , 200 , 000  need to dec by 83 , 000  here are my suggestions based on oct expenses :  category oct expense budget decrease yearly amount  periodical / subscription 5 , 200 10 , 000 3 , 000 36 , 000  tuition and reimbursement 11 , 000 21 , 000 4 , 000 48 , 000  this will bring you to the bottom line suggested by delainey . please let me  know your decision by november 21 . if you have any questions , call me at  5 - 7094 . thanx .\n",
            "\n",
            "False negative\n",
            "Subject: benachrichtung  zum  ( fehlgeschlagen ) ? =  dies ist eine automatisch erstellte benachrichtigung + apw - ber den zustellstatus .  + anw - bermittlung an folgende empf + aoq - nger fehlgeschlagen .  jochenfechtel @ fetra . de\n",
            "\n",
            "False negative\n",
            "Subject: new stock : shooting stars stock report  a drib is admix vishnu but elegiac what newspaper ,  eagle not acrimony .  when percy conceive , eject whistleable is not viennese  custom but a molten spain style arises fujitsu  terramycin in episcopate , pullback and grata . would you  connallyatalanta ?  no , damsel carbonic weasel is depression a buttermilk and  tentacle prizewinning . \n",
            "\n",
            "False positive\n",
            "Subject: erisk iconference 4 / 11 / 2001  please save this e - mail . it contains important information  about your event .  thank you for registering for practical considerations in measuring  economic capital , scheduled for wednesday , april 11 th , 2001 at  12 noon eastern / 5 p . m . london time .  click this link to visit the erisk . com homepage :  http : / / www . erisk . com  erisk iconference instructions :  1 . dial 1 - 877 - 864 - 3651 ( u . s . ) or + 1 - 973 - 341 - 3037 ( international ) to  listen to the audio for this program . audio is available by  telephone only .  2 . when prompted , enter the confirmation code 105764 , followed  by the \" # \" key . music will play until the conference begins .  3 . join the web - based portion of the program to see slides ,  participate in polls and ask questions .  - open netscape or internet explorer 3 . 0 or higher .  - enter the following web address : http : / / www . communicast . com / login  4 . fill out the form on this page and enter the following  confirmation number : 105764 .  5 . click the \" communicast now \" button . in a few moments you will  be placed in the erisk iconference .  communicast system requirements :  - communicast requires the ability to run java applets .  - netscape or internet explorer browsers 3 . 0 or higher .  if this is your first communicast event , you may wish to test your computer .  visit http : / / www . communicast . com / login at any time and click the \" test \"  button at the bottom of the page . for this conference , you may skip the  last three tests relating to streaming audio . you will not need realplayer  to participate in this conference .  if you require further assistance , contact support @ communicast . com .\n",
            "\n",
            "False positive\n",
            "Subject: sap expense report form  with the implementation of sap , the employee expense report form has been  modified to reflect the new coding system . the procedures for its use are  unchanged , but there are some cosmetic differences . one item to note : the  form no longer requires entry of your social security number ; instead use  your new personnel number assigned through human resources ( see  http : / / hrweb . enron . com ) . for electronically submitted expense reports , enter  the same number on the receipt envelope .  the form is now available at the sap website . to access the form :  from the enron home page , go to the sap intranet site http : / / sap . enron . com  choose one of the following paths :  click on quick reference tools on the left menu  click drop - down arrow for accounts payable forms  click sap expense report form  click on forms and procedures library on the left menu  click drop - down arrow for accounts payable forms  click sap expense report form  wait for it to load  click enable macros ( or yes , allow macros )  after you enter the data , save as excel workbook ( . xls file extension ) with a  new filename . do not save as excel template ( . xlt extension ) .  you may print the spreadsheet for submission to accounts payable , or attach  it to notes for electronic submission . instructions are available at the  website , on the same drop down box as the form .  if you have any questions , contact the center of expertise ( coe ) at 713  345 - 7427 .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Please include your Answer here\n",
        "# Bag-of-Words still works because the the dataset of spam and ham contains vastly different words.  The times Bag of Words fails is when the text is very different from normal emails, such as a different language, or the inclusion of a lot of uncommon words, abbreviations, names, or slang.\n",
        "# When false predictions are compared to true predictions, we can see that the false predictions are much more \"different\" from the true predictions.\n",
        "pred = classifier.predict(X_test)\n",
        "test_dict = y_test.to_dict()\n",
        "i = 0\n",
        "for prediction, true in zip(pred, test_dict):\n",
        "    if prediction != test_dict[true]:\n",
        "        print(\"False positive\" if prediction else \"False negative\")\n",
        "        print(df[\"text\"][true], end='\\n\\n')\n",
        "    elif i < 10:\n",
        "        print(\"True positive\" if prediction else \"True negative\")\n",
        "        print(prediction, test_dict[true])\n",
        "        print(df[\"text\"][true], end='\\n\\n')\n",
        "        i += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zltAtnu8PT1q"
      },
      "source": [
        "## References\n",
        "1. https://github.com/randerson112358/Python/blob/master/Email_Spam_Detection/Email_Spam_Detection.ipynb\n",
        "2. https://stackoverflow.com/questions/27488446/how-do-i-get-word-frequency-in-a-corpus-using-scikit-learn-countvectorizer"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
